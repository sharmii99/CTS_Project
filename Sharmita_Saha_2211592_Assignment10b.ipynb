{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f51133a",
   "metadata": {},
   "source": [
    "# Combating Hate Speech Using NLP and Machine Learning\n",
    "\n",
    "### Objective:\n",
    "\n",
    "Using NLP and ML, create a model to identify hate speech in Twitter.\n",
    "\n",
    "### Problem Statement:\n",
    "\n",
    "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium to spread hate.\n",
    "\n",
    "### Domain: Social Media\n",
    "\n",
    "### Analysis to be done: \n",
    "\n",
    "Clean up tweets and build a classification model by using NLP techniques, cleanup for tweets data, regularization and hyperparameter tuning using stratifies k-fold and cross validation to get the best model.\n",
    "\n",
    "### Content:\n",
    "id: identifier number of the tweet\n",
    "Label: 0(non-hate) / 1(hate)\n",
    "Tweet: the text in the tweet\n",
    "\n",
    "### Tasks:\n",
    "1. Load the tweets file using read_csv function from Pandas Package.\n",
    "2. Get the tweets into a list for easy text cleanup and manipulation\n",
    "3. To Cleanup:\n",
    "    * Normalize the casing\n",
    "    * Using regular expressions, remove user handles. These begin with '@'\n",
    "    * Using regular expressions, remove URLs.\n",
    "    * Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "    * Remove stopwords\n",
    "    * remove redundant terms like 'amp', 'rt', etc\n",
    "    * remove '#' symbols from the tweet while retaining the term\n",
    "4. Extra Cleanup by removing terms with a length of 1\n",
    "5. Check out the top terms in the tweets:\n",
    "    * First, get all the tokenized terms into one large list.\n",
    "    * Use the counter and find the 10 most common terms.\n",
    "6. Data Formatting for predictive modeling:\n",
    "    * Join the tokens back to form strings. This will be required for the vectorizers.\n",
    "    * Assign X and y.\n",
    "    * Perform train_test_split using sklearn\n",
    "7. We'll use TF-IDF values for the terms as a feature to get into a vector space model\n",
    "    * Import TF-IDf vectorizer from sklearn\n",
    "    * Instantiate with a maximum of 5000 terms in your vocabulary\n",
    "    * Fit and apply on the train set.\n",
    "    * Apply on the test set\n",
    "8. Model Building: Ordinary Logistic Regression\n",
    "    * Instantiate Logistic Regression from sklearn with default parameters.\n",
    "    * Fit into the train data\n",
    "    * Make predictions for the train and the test set\n",
    "9. Model Evaluation: Accuracy, recall and f1 score\n",
    "    * Report the accracy on the train set.\n",
    "    * Report the recall on the train set: decent, high or low\n",
    "    * Get the f1 score on the train set\n",
    "10. Looks like you need to adjust\n",
    "11. Train again with the adjustment and evaluate.\n",
    "    * Train the model on the train set\n",
    "    * Evaluate the predictions on the train set: accuracy, recall and f1 score\n",
    "12. Regularization and Hyperparameter tuning:\n",
    "    * Import Gridsearch and StratifiedKFold because of class imabalance.\n",
    "    * Provide the parameter grid to choose for 'C' and penalty parameters.\n",
    "    * Use a balanced class weight while instantiating the logistic regression\n",
    "13. Find the parameters with the best recall in cross validation\n",
    "    * Choose 'recall' as the metric for scoring\n",
    "    * Choose stratified 4 fold cross validation scheme\n",
    "    * Fit into the train set\n",
    "14. What are the best parameters?\n",
    "15. Predict and evaluate using the best estimator.\n",
    "    * Use the best estimator from the grid search to make predictions on the test\n",
    "    * What is the recall on the test set for the toxic comments?\n",
    "    * What is the f1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b33ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f97070",
   "metadata": {},
   "source": [
    "#### Read in the csv using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482962b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_tweets0 = pd.read_csv (\"Tweets_USA.csv\")\n",
    "inp_tweets0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21dc8680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_tweets0.label.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f0e8e",
   "metadata": {},
   "source": [
    "#### so we have around 7% of hate tweets in this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f64d68c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#thursdaythoughts  from @user  choose   #everyday '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_tweets0.tweet.sample().values[0]\n",
    "\n",
    "#checking the terms containing in a random tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b57be",
   "metadata": {},
   "source": [
    "#### Get the tweets into a list, for easy text clean up and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "112affc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets0 = inp_tweets0.tweet.values\n",
    "\n",
    "#getting them in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f89ca637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10194fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       "       \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       "       '  bihday your majesty',\n",
       "       '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       "       ' factsguide: society now    #motivation'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets0[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a8f28",
   "metadata": {},
   "source": [
    "#### So as we can see here, The tweets contain:\n",
    "\n",
    "1. URLs\n",
    "2. Hashtags\n",
    "3. user handles\n",
    "4. 'RT'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae36e",
   "metadata": {},
   "source": [
    "### Cleaning up the data\n",
    "\n",
    "#### Normalizing the casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "018bc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_lower = [twt.lower() for twt in tweets0] \n",
    "\n",
    "#to avoid case sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f66a653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_lower[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d41fe",
   "metadata": {},
   "source": [
    "### Removing user handles that begin with '@'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bac9cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "836432bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' this course rocks! http://rahimbaig.com/ai'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"@\\w+\",\"\", \"@Rahim this course rocks! http://rahimbaig.com/ai\")\n",
    "\n",
    "#substituting using regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eee91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_nouser = [re.sub(\"@\\w+\",\"\",twt) for twt in tweets_lower] \n",
    "\n",
    "#doing the same for the whole list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e4aee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_nouser[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08392307",
   "metadata": {},
   "source": [
    "#### Now it looks a little bit cleaner as all the user handles are removed here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add47e32",
   "metadata": {},
   "source": [
    "### Removing URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a71bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@Rahim this course rocks! '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"\\w+://\\S+\",\"\", \"@Rahim this course rocks! http://rahimbaig.com/ai\")\n",
    "\n",
    "#the + sign after S is important. as withouit this the output will contain the 'http://rahimbaig.com/ai' part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf618073",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_nourl = [re.sub(\"\\w+://\\S+\",\"\", twt) \n",
    "                for twt in tweets_nouser]\n",
    "#doing same for the whole list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43d5fb3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_nourl[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77fdc4",
   "metadata": {},
   "source": [
    "#### Now we can see that there is no URL  present in the tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e31564",
   "metadata": {},
   "source": [
    "#### Tokenzing the Tweets into individual terms using TweetTokenizer from NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c922ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e2e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkn = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ae3ca60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n"
     ]
    }
   ],
   "source": [
    "print(tkn.tokenize(tweets_nourl[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b08e092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['got', 'a', 't-shi', 'and', 'mini-sticker', 'for', \"father's\", 'day', '!', '!', 'just', 'need', 'to', 'get', 'a', 'magnet', 'to', 'complete', 'the', 'collection', '!']\n"
     ]
    }
   ],
   "source": [
    "tweet_token = [tkn.tokenize(sent) for sent in tweets_nourl]\n",
    "#print(tweet_token[31000])\n",
    "print(tweet_token[12345])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b84e3",
   "metadata": {},
   "source": [
    "### Remove punctuations and stop words and other redundant terms like 'rt', 'amp' etc\n",
    "\n",
    "* Also remove hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a015f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\2211592\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "940f41e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_nltk = stopwords.words(\"english\")\n",
    "stop_punct = list(punctuation)\n",
    "stop_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62f64330",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_punct.extend(['...', '``', \"''\",\"..\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2c8b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_context = ['rt', 'amp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e93e45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_final = stop_nltk + stop_punct + stop_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3d58f",
   "metadata": {},
   "source": [
    "#### creating a function to:\n",
    "\n",
    "* remove stop words from a single sentence\n",
    "* remove # tags\n",
    "* remove terms with length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b5057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop(sent):\n",
    "    return [re.sub(\"#\",\"\",term) for term in sent if ((term not in stop_final) & (len(term)>1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72ead838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['got',\n",
       " 't-shi',\n",
       " 'mini-sticker',\n",
       " \"father's\",\n",
       " 'day',\n",
       " 'need',\n",
       " 'get',\n",
       " 'magnet',\n",
       " 'complete',\n",
       " 'collection']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del_stop(tweet_token[4])\n",
    "del_stop(tweet_token[12345])\n",
    "#trying the function on one random tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44d723b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = [del_stop(tweet) for tweet in tweet_token]\n",
    "\n",
    "#applying on the whole list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604c021",
   "metadata": {},
   "source": [
    "### Checking out the top terms in the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36408103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11926a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = []\n",
    "for tweet in tweets_clean:\n",
    "    term_list.extend(tweet)\n",
    "#getting all the tokenized terms into one list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b0a30c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2748),\n",
       " ('day', 2276),\n",
       " ('happy', 1684),\n",
       " ('time', 1131),\n",
       " ('life', 1118),\n",
       " ('like', 1047),\n",
       " (\"i'm\", 1018),\n",
       " ('today', 1013),\n",
       " ('new', 994),\n",
       " ('thankful', 946)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = Counter(term_list)\n",
    "res.most_common(10)\n",
    "\n",
    "#using the counter to get the 10 most common terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa041a",
   "metadata": {},
   "source": [
    "### Data Formatting for Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39b8784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['never', 'msg', 'first', 'dun', 'msg', 'first', 'disappointed']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean[30000]\n",
    "\n",
    "#checking the tokens for one random tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d7c4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = [\" \".join(tweet) for tweet in tweets_clean]\n",
    "# joining the tokens back to string form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aee64cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'never msg first dun msg first disappointed'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_clean[30000]\n",
    "#checking the strings for one random tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c01cae",
   "metadata": {},
   "source": [
    "### Separating X and y and performing train test split, 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1022c371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31962"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25d18161",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweets_clean\n",
    "y = inp_tweets0.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991708b4",
   "metadata": {},
   "source": [
    "#### Train Test Split using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6304357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19aa71e9",
   "metadata": {},
   "source": [
    "### Create a document term matrix using count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19ffa183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0932986",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "\n",
    "#instantiating with a maximum of 5000 terms in our vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c3aa233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22373, 9589)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69c4076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55170d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 5000), (9589, 5000))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape, X_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d82f644",
   "metadata": {},
   "source": [
    "### Model Building\n",
    "\n",
    "#### Using a simple logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6679ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c28fecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b374206b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f35d1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = logreg.predict(X_train_bow)\n",
    "y_test_pred = logreg.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "17204c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "309a7870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9560184150538595"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0b9c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     20815\n",
      "           1       0.96      0.39      0.55      1558\n",
      "\n",
      "    accuracy                           0.96     22373\n",
      "   macro avg       0.96      0.69      0.76     22373\n",
      "weighted avg       0.96      0.96      0.95     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff433ae4",
   "metadata": {},
   "source": [
    "#### Here, weighted average for recall is 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef01e1b",
   "metadata": {},
   "source": [
    "### Adjusting for class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7285d18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(class_weight = \"balanced\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "637fba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b27c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = logreg.predict(X_train_bow)\n",
    "y_test_pred = logreg.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "17fb5eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9527108568363652"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0babbc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     20815\n",
      "           1       0.60      0.97      0.74      1558\n",
      "\n",
      "    accuracy                           0.95     22373\n",
      "   macro avg       0.80      0.96      0.86     22373\n",
      "weighted avg       0.97      0.95      0.96     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ef66b3",
   "metadata": {},
   "source": [
    "#### Here, weighted average for recall is 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626b3063",
   "metadata": {},
   "source": [
    "### Regularization and Hyperparameter tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93d80dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "# importing these libraries because of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ddcb7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 0.5, 1, 5, 10]\n",
    "}\n",
    "\n",
    "# [0.01, 0.1, 0.5, 1, 5, 10] we can use this also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6f74da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_lr = LogisticRegression(class_weight = \"balanced\")\n",
    "\n",
    "#using a balanced class weight while instantiating the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ae4b03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the grid search model\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier_lr,\n",
    "                           param_grid = param_grid,\n",
    "                           cv = StratifiedKFold(4),\n",
    "                           n_jobs = -1, verbose = 1,\n",
    "                           scoring = \"recall\" )\n",
    "\n",
    "#choosing recall as the metric for scoring and stratified 4 fold cross validation scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b343c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(class_weight='balanced'), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 0.5, 1, 5, 10]}, scoring='recall',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5be0b3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight='balanced')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc94e356",
   "metadata": {},
   "source": [
    "### Using the best estimator to make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9937e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "906cbe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search.best_estimator_.predict(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d9b9eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96      8905\n",
      "           1       0.47      0.78      0.59       684\n",
      "\n",
      "    accuracy                           0.92      9589\n",
      "   macro avg       0.73      0.86      0.77      9589\n",
      "weighted avg       0.95      0.92      0.93      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720048b5",
   "metadata": {},
   "source": [
    "#### Here, weighted average for recall is 0.92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe87d3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
